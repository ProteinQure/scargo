apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: scargo-full-artifacts-
spec:
  volumes:
    - name: workdir
      emptyDir: {}

  arguments:
    parameters:
      - name: input-val
        value: "1"
      - name: pre-word
        value: "pre"
      - name: post-word
        value: "post"
      - name: num-alphas
        value: "3"
      - name: s3-bucket
        value: pq-dataxfer-tmp
      - name: input-path
        value: scargo/inputs
      - name: input-csv
        value: input_csv.csv
      - name: output-path
        value: testing/scargo-examples/output
      - name: optimized
        # valid values are `cpu`, `memory`
        value: cpu

  entrypoint: main

  templates:
    - name: main
      steps:
        - - name: get-nth-word-compute
            template: exec-get-nth-word
            arguments:
              parameters:
                - name: word-index
                  value: "{{workflow.parameters.input-val}}"
              artifacts:
                - name: csv-file
                  s3:
                    endpoint: s3.amazonaws.com
                    bucket: "{{workflow.parameters.s3-bucket}}"
                    key: "{{workflow.parameters.input-path}}/{{workflow.parameters.input-csv}}"

        - - name: add-multi-alpha-compute
            template: exec-add-multi-alpha
            arguments:
              parameters:
                - name: init-value
                  value: "{{steps.get-nth-word-compute.outputs.parameters.out-val}}"
                - name: num-alphas
                  value: "{{workflow.parameters.num-alphas}}"
              artifacts:
                - name: init-file
                  from: "{{steps.get-nth-word-compute.outputs.artifacts.out-file}}"

    - name: exec-get-nth-word
      inputs:
        parameters:
          - name: word-index
        artifacts:
          - name: csv-file
            path: /workdir/in/input.csv
      outputs:
        parameters:
          - name: out-val
            valueFrom:
              path: /workdir/out/out-val.txt
        artifacts:
          - name: out-file
            path: /workdir/out/out-file.txt
      initContainers:
        - name: mkdir
          image: alpine:latest
          command: ["mkdir", "-p", "/workdir/out", "/workdir/in"]
          mirrorVolumeMounts: true
        - name: chmod
          image: alpine:latest
          command: ["chmod", "-R", "a+rwX", "/workdir"]
          mirrorVolumeMounts: true
      script:
        image: python:alpine
        command: [python]
        source: |
          with open("{{inputs.artifacts.csv-file.path}}", "r") as fi:
              words = fi.readline().split(",")

          word = words[int({{inputs.parameters.word-index}})]

          with open("{{outputs.parameters.out-val.path}}", "w+") as fi:
              fi.write(word)

          with open("{{outputs.artifacts.out-file.path}}", "w+") as fi:
              fi.write(f"{{workflow.parameters.pre-word}},{word},{{workflow.parameters.post-word}}")

        resources:
          requests:
            memory: 30Mi
            cpu: 20m
          limits:
            memory: 30Mi
            cpu: 20m
        volumeMounts:
          - name: workdir
            mountPath: /workdir

    - name: exec-add-multi-alpha
      inputs:
        parameters:
          - name: init-value
          - name: num-alphas
        artifacts:
          - name: init-file
            path: /workdir/in/init-file.txt
      outputs:
        artifacts:
          - name: txt-out
            path: /workdir/out
            archive:
              none: {}
            s3:
              endpoint: s3.amazonaws.com
              bucket: "{{workflow.parameters.s3-bucket}}"
              key: "{{workflow.parameters.output-path}}"
      initContainers:
        - name: mkdir
          image: alpine:latest
          command: ["mkdir", "-p", "/workdir/out", "/workdir/in"]
          mirrorVolumeMounts: true
        - name: chmod
          image: alpine:latest
          command: ["chmod", "-R", "a+rwX", "/workdir"]
          mirrorVolumeMounts: true
      script:
        image: python:alpine
        command: [python]
        source: |
          with open("{{inputs.artifacts.init-file.path}}", "r") as fi:
              prev_line = fi.readline()

          alphas = {{inputs.parameters.num-alphas}} * "a"
          new_word = alphas + "{{inputs.parameters.init-value}}" + alphas

          with open("{{outputs.artifacts.txt-out.path}}/full_artifacts_{{inputs.parameters.init-value}}.txt", "w+") as fi:
              fi.write(prev_line)
              fi.write(f"{{workflow.parameters.pre-word}},{new_word},{{workflow.parameters.post-word}}")

        resources:
          requests:
            memory: 30Mi
            cpu: 20m
          limits:
            memory: 30Mi
            cpu: 20m
        volumeMounts:
          - name: workdir
            mountPath: /workdir